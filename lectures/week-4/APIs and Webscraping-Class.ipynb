{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda - API's & WebScrapiing\n",
    "\n",
    "- Logistics \n",
    "\n",
    "- What is API?\n",
    "\n",
    "- Why to use API?\n",
    "\n",
    "- Some Examples of API's\n",
    "\n",
    "- Types of HTTP Status codes\n",
    "\n",
    "- Token's and authentication\n",
    "\n",
    "- [Github API](https://developer.github.com/v3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hw-1\n",
    "\n",
    "- Extension (optional) to 09/24 4:30 PM\n",
    "\n",
    "- If you want to submit right now: You will get 2pts (out of 10) bonus.\n",
    "\n",
    "- [Google Form](https://forms.gle/Y3T4ycudhr9Yb4z26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hw-2\n",
    "\n",
    "- Due Date: Week-9 (10/08 - Thursday 4:30 PM)\n",
    "\n",
    "- Data acquisition (Either with an API or web scraping) and wrangling\n",
    "\n",
    "- Deliverables: Same as the first homework\n",
    "\n",
    "    - Github Repo with organized ReadMe\n",
    "    - Clean code for scraping - using API\n",
    "    - A report notebook (Technical Notebook)\n",
    "    \n",
    "- [A Perfect Example](https://github.com/tgel0/spotify-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is an API?\n",
    "\n",
    "API: __A__plication __P__rogramming __I__nterface\n",
    "\n",
    "\"It defines a way for services and products to communicate with each other through a documented interface\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Why to use an API?__\n",
    "\n",
    "- Share data easily\n",
    "\n",
    "- Control/track shared data\n",
    "\n",
    "- For users: CSV's as static - data changes rapidly\n",
    "\n",
    "- You don't want to save all of the data -  You need only a smaller relevant part of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- \"Some APIs, like the Reddit and Spotify APIs, are designed to expand the reach of the organization by making their data available to users, and enabling external developers to build products that are in some way reliant on the business, and so keep customers coming back. For example, Spotify featured the “artist explorer” in the hopes that users will find new artists, build new playlists, and therefore continue (or start) using Spotify.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://medium.com/@TebbaVonMathenstien/what-is-an-api-and-why-should-i-use-one-863c3365726b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Some Examples__\n",
    "\n",
    "[Google Geolocation API](https://developers.google.com/maps/documentation/geolocation/overview)\n",
    "\n",
    "[Spotify Web API](https://developer.spotify.com/documentation/web-api/)\n",
    "\n",
    "[Twitter API](https://help.twitter.com/en/rules-and-policies/twitter-api)\n",
    "\n",
    "[Sklearn API?](https://scikit-learn.org/stable/modules/classes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example API: wikipedia__\n",
    "\n",
    "[API's Documentation](https://pypi.org/project/wikipedia/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!conda install -c conda-forge --yes --prefix {sys.prefix} wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me an inputData Science\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from many structural and unstructured data. Data science is related to data mining, machine learning and big data.\\nData science is a \"concept to unify statistics, data analysis and their related methods\" in order to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, domain knowledge and information science. Turing award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\\n\\n'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's import wikipedia - Make sure you installed it before importing\n",
    "import wikipedia\n",
    "\n",
    "## let's get some data with .page method\n",
    "ds = wikipedia.page(\"Data Science\")\n",
    "\n",
    "## check summary, content, section, title, etc.\n",
    "def app():\n",
    "    word = input(\"Give me an input\")\n",
    "    return wikipedia.page(word).summary\n",
    "app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[IBM - What is an API](https://developer.ibm.com/apiconnect/docs/what-is-an-api/)\n",
    "[Wiki - API](https://en.wikipedia.org/wiki/API)\n",
    "\n",
    "[What is an API - Why Should I Use It?](https://medium.com/@TebbaVonMathenstien/what-is-an-api-and-why-should-i-use-one-863c3365726b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__What is a REST API?__\n",
    "\n",
    "\"A REST API is a web service that uses the REST (Representational State Transfer) architecture to handle a request on a frontend web service.\"\n",
    "\n",
    "[Source: IBM - What is a REST API](https://www.ibm.com/cloud/learn/rest-apis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__What are the actions we can do with REST__\n",
    "\n",
    "- GET: To Request data from a specified resource.\n",
    "\n",
    "- POST: To send data to a server to create/update a resource.\n",
    "\n",
    "- PUT: To send data to a server to create/update a resource.\n",
    "\n",
    "- DELETE: To delete the specified resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://www.w3schools.com/tags/ref_httpmethods.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Python Requests Library__\n",
    "\n",
    "\"Requests is an elegant and simple HTTP library for Python, built for human beings.\"\n",
    "\n",
    "First Let's make sure that `requests` library is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python Requests Library](https://requests.readthedocs.io/en/master/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## requests library installation\n",
    "import sys\n",
    "!conda install -c conda-forge --yes --prefix {sys.prefix} requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's see what are the some of the things we can do with `requests` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## first import requests library\n",
    "import requests\n",
    "## The most simple/basic thing we will do with requests library\n",
    "## is to make a request\n",
    "\n",
    "r = requests.get('https://api.github.com/events')\n",
    "\n",
    "## r is an Response object\n",
    "type(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Response Content__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can read the content of the server's response\n",
    "\n",
    "## .text return string valued response- make educated guess about the encoding\n",
    "\n",
    "r.text\n",
    "## .content returns bytes - for non-text requests\n",
    "\n",
    "r.content\n",
    "## If you know that you are getting the data in json format:\n",
    "r.json()[3]\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we can check the status code of a response\n",
    "\n",
    "## note that bad responses will have different status code\n",
    "bad_r = requests.get('https://httpbin.org/status/404')\n",
    "\n",
    "## in our code if we want we can raise errors with .raise_for_status method\n",
    "bad_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[For More on Requests](https://requests.readthedocs.io/en/master/user/quickstart/#make-a-request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__HTTP Status Codes__\n",
    "\n",
    "* 200 — everything went okay, and the result has been returned (if any)\n",
    "* 301 — the server is redirecting you to a different endpoint. This can happen when a company switches domain names, or an endpoint name is changed.\n",
    "* 401 — the server thinks you’re not authenticated. This happens when you don’t send the right credentials to access an API (we’ll talk about authentication in a later post).\n",
    "* 400 — the server thinks you made a bad request. This can happen when you don’t send along the right data, among other things.\n",
    "* 403 — the resource you’re trying to access is forbidden — you don’t have the right permissions to see it.\n",
    "* 404 — the resource you tried to access wasn’t found on the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[Digital Ocean Tutorial](https://www.digitalocean.com/community/tutorials/how-to-troubleshoot-common-http-error-codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Let's see requests library in action__\n",
    "\n",
    "[Open Notify API](http://open-notify.org/Open-Notify-API/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Response' object has no attribute 'header'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-71cc2ad7eec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m## What is the content of the response? Let's make is prettier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Response' object has no attribute 'header'"
     ]
    }
   ],
   "source": [
    "## let's Use International Space Station's API\n",
    "response = requests.get(\"http://api.open-notify.org/iss-now.json\")\n",
    "\n",
    "## Let's check the status code of the response\n",
    "response.json()\n",
    "## What is the content of the response? Let's make is prettier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-17T18:09:57\n"
     ]
    }
   ],
   "source": [
    "## converting timestamps to readable format\n",
    "from datetime import datetime\n",
    "readable = datetime.fromtimestamp(response.json()['timestamp']).isoformat()\n",
    "print(readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: BAD REQUEST for url: http://api.open-notify.org/iss-pass.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-f4e01db18fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbad_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## check the status code / note that there is still content in response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbad_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: BAD REQUEST for url: http://api.open-notify.org/iss-pass.json"
     ]
    }
   ],
   "source": [
    "## here is an example of a failed request\n",
    "bad_response = requests.get(\"http://api.open-notify.org/iss-pass.json\")\n",
    "bad_response.status_code\n",
    "## check the status code / note that there is still content in response\n",
    "bad_response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WebScraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## let's make sure that you have beautifulsoup installed\n",
    "!conda install -c conda-forge --yes --prefix {sys.prefix} beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## don't forget to import beautifulsoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## Here I copied a toy case scenerio\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[Source](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "## Create a Soup object\n",
    "## This is the first step for parsing html\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "## let's check soup and print it as html file with .prettify()\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Note that all this code is just for 2 lines of text :) __\n",
    "\n",
    "<html>\n",
    " <head>\n",
    "  <title>\n",
    "   The Dormouse's story\n",
    "  </title>\n",
    " </head>\n",
    " <body>\n",
    "  <p class=\"title\">\n",
    "   <b>\n",
    "    The Dormouse's story\n",
    "   </b>\n",
    "  </p>\n",
    "  <p class=\"story\">\n",
    "   Once upon a time there were three little sisters; and their names were\n",
    "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
    "    Elsie\n",
    "   </a>\n",
    "   ,\n",
    "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
    "    Lacie\n",
    "   </a>\n",
    "   and\n",
    "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
    "    Tillie\n",
    "   </a>\n",
    "   ;\n",
    "and they lived at the bottom of a well.\n",
    "  </p>\n",
    "  <p class=\"story\">\n",
    "   ...\n",
    "  </p>\n",
    " </body>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check title\n",
    "soup.title\n",
    "## check title's parent\n",
    "soup.title.parent\n",
    "## let's list the children of the body\n",
    "\n",
    "list(soup.body.children)\n",
    "## let's find_all paragraphs in the body\n",
    "len(soup.body.find_all(\"p\"))\n",
    "## find the first paragraph and then its siblings\n",
    "list(soup.body.p.next_siblings)\n",
    "\n",
    "soup.body.find_all(\"p\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Let's See Beautiful Soup in Action__\n",
    "\n",
    "[Heat Hot Sauce Shop](https://heathotsauce.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <Response [200]>\n",
      "2 <Response [200]>\n",
      "3 <Response [200]>\n",
      "4 <Response [200]>\n",
      "5 <Response [200]>\n",
      "6 <Response [200]>\n",
      "7 <Response [200]>\n",
      "8 <Response [200]>\n",
      "9 <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# scrape all 10 pages to get names and urls\n",
    "\n",
    "names = []\n",
    "urls = []\n",
    "\n",
    "# go to each page (print progress)\n",
    "for i in range(1, 10):\n",
    "    url = 'https://heathotsauce.com/collections/all?page=' + str(i)\n",
    "    page = requests.get(url)\n",
    "    print (i, page)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #in each page, scrape the names\n",
    "    for j in soup.findAll('span', class_='title product-name-custom'):\n",
    "        names.append(j.get_text())\n",
    "    for k in soup.findAll(itemprop = 'url'):\n",
    "        urls.append(k.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#combine names and urls into a df\n",
    "names_urls = pd.DataFrame({'names':names, 'urls':urls})\n",
    "\n",
    "# add url to start of urls\n",
    "names_urls['urls'] = names_urls['urls'].apply(lambda x: 'https://heathotsauce.com' + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://heathotsauce.com/collections/all/products/reaper-puree-1'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_urls.iloc[2].urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'512 Pot Sauce'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_urls.names[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <Response [200]>\n",
      "1 <Response [200]>\n",
      "2 <Response [200]>\n",
      "3 <Response [200]>\n",
      "4 <Response [200]>\n",
      "5 <Response [200]>\n",
      "6 <Response [200]>\n",
      "7 <Response [200]>\n",
      "8 <Response [200]>\n",
      "9 <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "## Go to each unique url, grab name, price, manufacturer, description\n",
    "\n",
    "## NOTE: I requested too many timesand was timed out. \n",
    "## Do this in batches, save as different df, then concat together\n",
    "\n",
    "name = []\n",
    "mfc = []\n",
    "price = []\n",
    "desc = []\n",
    "urls = []\n",
    "\n",
    "for n, url in enumerate(names_urls['urls'][:10]):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "#     name\n",
    "    try:\n",
    "        name.append(soup.find('h1', class_='product_name').get_text())\n",
    "    except:\n",
    "        name.append('')\n",
    "#     manufacturer\n",
    "    try:\n",
    "        mfc.append(soup.find('p', class_='vendor').get_text())\n",
    "    except:\n",
    "        mfc.append('')\n",
    "#     price\n",
    "    try:\n",
    "        price.append(soup.find('span', class_='money').get_text())\n",
    "    except:\n",
    "        price.append('')\n",
    "#     description\n",
    "    try:\n",
    "        desc.append(soup.find('div', class_='description').get_text())\n",
    "    except:\n",
    "        desc.append('')\n",
    "#     url\n",
    "    try:\n",
    "        urls.append(url)\n",
    "    except:\n",
    "        urls.append('')\n",
    "    \n",
    "#     print progress, if response != 200, stop kernel. you have been timed out\n",
    "    print (n, page)\n",
    "\n",
    "df_1 = pd.DataFrame({'names':name,\n",
    "                   'mfc':mfc,\n",
    "                   'price':price,\n",
    "                   'desc':desc,\n",
    "                   'url':urls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# combine all df batches. strip manufacturers of \\n\n",
    "full_df = df_1\n",
    "full_df['mfc'] = full_df['mfc'].apply(lambda x: x.strip())\n",
    "full_df['desc'] = full_df['desc'].apply(lambda x: x.strip())\n",
    "\n",
    "# remove gift sets and empty rows\n",
    "full_df = full_df[full_df['mfc'] != 'Gift Set']\n",
    "full_df = full_df[full_df['desc'] != '']\n",
    "full_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# save df as csv\n",
    "full_df.to_csv('hot_sauces.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This 25th Anniversary Gold Edition Sauce is made with No. 9 Plutonium which is a 9 million Scoville Heat Unit extract. Reaper, Scorpion and Ghost peppers send this over the top hot sauce into heat realms unparalleled\\xa0by most other sauces.\\xa0\\xa0\\nHeat Level: Extreme\\nIngredients:\\xa0Reaper, Scorpion & Ghost Peppers, Red Wine Vinegar, White Distilled Vinegar, Fresh Chopped Onion & Garlic, Water, Natural Sugar, Fresh Lime Juice, Chile Extract & Xanthan Gum.\\xa0\\nContains Pepper Extract\\n5 oz'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[0].desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Extra Material: Back to Request -- Query Parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'success',\n",
       " 'request': {'altitude': 100,\n",
       "  'datetime': 1600374218,\n",
       "  'latitude': 40.71,\n",
       "  'longitude': -74.0,\n",
       "  'passes': 5},\n",
       " 'response': [{'duration': 599, 'risetime': 1600385039},\n",
       "  {'duration': 648, 'risetime': 1600390811},\n",
       "  {'duration': 580, 'risetime': 1600396691},\n",
       "  {'duration': 571, 'risetime': 1600402568},\n",
       "  {'duration': 640, 'risetime': 1600408387}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latitude =  38.53\n",
    "Longitude = - 77.02\n",
    "\n",
    "parameters = {\"lat\": 40.71, \"lon\": -74}\n",
    "\n",
    "\n",
    "# Make a get request with the parameters.\n",
    "response = requests.get(\"http://api.open-notify.org/iss-pass.json\", params=parameters)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-18T01:53:07\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "readable = datetime.fromtimestamp(1600408387).isoformat()\n",
    "print(readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': 3,\n",
       " 'people': [{'craft': 'ISS', 'name': 'Chris Cassidy'},\n",
       "  {'craft': 'ISS', 'name': 'Anatoly Ivanishin'},\n",
       "  {'craft': 'ISS', 'name': 'Ivan Vagner'}],\n",
       " 'message': 'success'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= requests.get(\"http://api.open-notify.org/astros.json\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Extra Material:  Yelp - Getting Access Tokens__\n",
    "\n",
    "With that, lets go grab an access token from an API site and make some API calls!\n",
    "Point your browser over to this [yelp page](https://www.yelp.com/developers/v3/manage_app) and start creating an app in order to obtain and api access token:\n",
    "\n",
    "You can either sign in to an existing Yelp account, or create a new one, if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/yelpapp.png\" width = 550>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./secrets.cfg']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./secrets.cfg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "client_id = config['Yelp']['ClientId']\n",
    "api_key = config['Yelp']['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<class 'str'>\n",
      "{\"businesses\": [{\"id\": \"094fHChJkrJqztSFCn3ezA\", \"alias\": \"taqueria-habanero-washington\", \"name\": \"Taqueria Habanero\", \"image_url\": \"https://s3-media4.fl.yelpcdn.com/bphoto/Sy684B1dgmVmk9SQQ2HLSQ/o.jpg\", \"is_closed\": false, \"url\": \"https://www.yelp.com/biz/taqueria-habanero-washington?adjust_creative=sHfPIWw2qKXvXAWiQlx3YA&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=sHfPIWw2qKXvXAWiQlx3YA\", \"review_count\": 840, \"categories\": [{\"alias\": \"mexican\", \"title\": \"Mexican\"}, {\"alias\": \"cocktailbars\", \"title\": \"Cocktail Bars\"}], \"rating\": 4.5, \"coordinates\": {\"latitude\": 38.93755, \"longitude\": -77.03309}, \"transactions\": [\"delivery\"], \"price\": \"$$\", \"location\": {\"address1\": \"3710 14th St NW\", \"address2\": null, \"address3\": \"\", \"city\": \"Washington, DC\", \"zip_code\": \"20010\", \"country\": \"US\", \"state\": \"DC\", \"display_address\": [\"3710 14th St NW\", \"Washington, DC 20010\"]}, \"phone\": \"+12027227700\", \"display_phone\": \"(202) 722-7700\", \"distance\": 2926.6099864285006}, {\"id\": \"H7\n"
     ]
    }
   ],
   "source": [
    "term = 'Mexican'\n",
    "location = 'Washington DC'\n",
    "SEARCH_LIMIT = 10\n",
    "\n",
    "url = 'https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "headers = {\n",
    "        'Authorization': 'Bearer {}'.format(api_key),\n",
    "    }\n",
    "\n",
    "url_params = {\n",
    "                'term': term,\n",
    "                'location': location,\n",
    "                'limit': SEARCH_LIMIT\n",
    "            }\n",
    "response = requests.get(url, headers=headers, params=url_params)\n",
    "print(response)\n",
    "print(type(response.text))\n",
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'SzpCnlr3SVfGsHganyhxNQ',\n",
       " 'alias': 'tacos-el-chilango-washington',\n",
       " 'name': 'Tacos El Chilango',\n",
       " 'image_url': 'https://s3-media1.fl.yelpcdn.com/bphoto/bJ7LGmelTPcrK4RM07K-FQ/o.jpg',\n",
       " 'is_closed': False,\n",
       " 'url': 'https://www.yelp.com/biz/tacos-el-chilango-washington?adjust_creative=sHfPIWw2qKXvXAWiQlx3YA&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=sHfPIWw2qKXvXAWiQlx3YA',\n",
       " 'review_count': 290,\n",
       " 'categories': [{'alias': 'mexican', 'title': 'Mexican'}],\n",
       " 'rating': 4.0,\n",
       " 'coordinates': {'latitude': 38.9183867798767, 'longitude': -77.0278090846558},\n",
       " 'transactions': ['delivery'],\n",
       " 'price': '$',\n",
       " 'location': {'address1': '1119 V St NW',\n",
       "  'address2': '',\n",
       "  'address3': '',\n",
       "  'city': 'Washington, DC',\n",
       "  'zip_code': '20009',\n",
       "  'country': 'US',\n",
       "  'state': 'DC',\n",
       "  'display_address': ['1119 V St NW', 'Washington, DC 20009']},\n",
       " 'phone': '+12029863030',\n",
       " 'display_phone': '(202) 986-3030',\n",
       " 'distance': 825.8725976163965}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['businesses'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.yelp.com/v3/businesses/search?term=Mexican&location=Washington+DC&limit=10'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "[Python APIs](https://www.pythonforbeginners.com/api/list-of-python-apis)\n",
    "\n",
    "[HTTP Status Codes](https://httpstatuses.com/101)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
