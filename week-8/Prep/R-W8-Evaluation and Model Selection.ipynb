{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Model Selection\n",
    "\n",
    "\n",
    "[From Introduction to Statistical Learning with R (ISLR)](https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n",
    "\n",
    "\n",
    "Read 5.1: Cross Validation p175 - p187\n",
    "\n",
    "__Some points to keep in your mind as you're reading__\n",
    "\n",
    "- Make sure you really understand the difference between `test error rate` and `train error rate`.\n",
    "\n",
    "- What is the challenge of estimating the `test error rate`?\n",
    "\n",
    "- Can we use `train error rate` as an estimate for `test error rate`? Why (Why not)?\n",
    "\n",
    "- Explain `validation set approach`.\n",
    "\n",
    "- What is the difference between `train set` and `validation set`?\n",
    "\n",
    "- Do you fit the model on `validation set`?\n",
    "\n",
    "- Understand figure 5.2\n",
    "\n",
    "- What is `validation error rate`? Does `validation error rate` overestimate or underestimate `test error rate`?\n",
    "\n",
    "- What weakness of `validation set approach` is addressed by `Leave-One-Out Cross Validation` (LOOC) and how?\n",
    "\n",
    "- What is the major advantage of the LOOC with respect to `validation set approach`?\n",
    "\n",
    "- What is the major disadvantage of the LOOC with respect to `validation set approach`?\n",
    "\n",
    "- What is magic formula in the context of LOOC? Why is it magical?\n",
    "\n",
    "- Explain `k-fold cross validation` approach.\n",
    "\n",
    "- Compare the advantages and disadvantages of `k-fold cross validation` with respect to previous approached.\n",
    "\n",
    "- What might be some possible goals when we perform cross-validation?\n",
    "\n",
    "- Compare LOOC and cross-validation with respect to concerns about `bias`?\n",
    "\n",
    "- Which one of the approaches between LOOC and cross-validation has smaller variance? Do you understand why?\n",
    "\n",
    "Read 6.2: Shrinkage Methods p214 - p230\n",
    "\n",
    "- How Ridge regression adjusts the RSS formula and why?\n",
    "\n",
    "- What is `shrinkage penalty` and what is it role in formula 6.5?\n",
    "\n",
    "- What happens if you set $\\lambda$ very big? What if very small?\n",
    "\n",
    "- Explain $\\ell_{2}$-norm. Consider the vector $v = (3,4,5)$ what would be the $\\ell_{2}$-norm of this vector?\n",
    "\n",
    "- Explain `scale equivariance`. Is Ridge algorithm `scale equivariant`?\n",
    "\n",
    "- Compare Ridge regression with respect to least squares approach. Which one has less variance? Which one would have more bias?\n",
    "\n",
    "- When does Ridge regression work best?\n",
    "\n",
    "- Compare Lasso and Ridge regression.\n",
    "\n",
    "- Explain what is a sparse model.\n",
    "\n",
    "- You can stop at p220 in your first reading as things get a little bit technical after that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
